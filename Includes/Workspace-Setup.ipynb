{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Databricks notebook source\n",
        "# MAGIC %md\n",
        "# MAGIC\n",
        "# MAGIC # Workspace Setup\n",
        "# MAGIC Instructors should run this notebook to prepare the workspace for a class.\n",
        "# MAGIC\n",
        "# MAGIC This creates or updates the following resources:\n",
        "# MAGIC\n",
        "# MAGIC |Resource Type|Description|\n",
        "# MAGIC |---|---|\n",
        "# MAGIC |User Entitlements|User-specific grants to allow creating databases/schemas against the current catalog when they are not workspace-admins.|\n",
        "# MAGIC |Instance Pool | **DBAcademy** for use by students and the \"student\" and \"jobs\" policies|\n",
        "# MAGIC |Cluster Policies| **DBAcademy** for clusters running standard notebooks <br> **DBAcademy Jobs** for workflows/jobs <br> **DBAcademy DLT** for DLT piplines (automatically applied)|\n",
        "# MAGIC |Shared SQL Warehouse|**DBAcademy Warehouse** for Databricks SQL exercises|\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "# MAGIC %run ./_common\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "# Start a timer so we can benchmark execution duration.\n",
        "setup_start = dbgems.clock_start()\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "# MAGIC %md\n",
        "# MAGIC ## Get Class Config Parameters\n",
        "# MAGIC Sets up the following widgets to collect parameters used to configure our environment as a means of controlling class cost.\n",
        "# MAGIC\n",
        "# MAGIC - **Configure For** (required) - **All Users**, **Missing Users Only**, or **Current User Only**\n",
        "# MAGIC - **Description** (optional) - a general purpose description of the class\n",
        "# MAGIC - **Lab/Class ID** (optional) - **lab_id** is the name assigned to this event/class or alternatively its class number\n",
        "# MAGIC - **Spark Version** (optional) - **spark_version** is the \"preloaded\" and thus default version of the Databricks Runtime\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "from dbacademy.dbhelper import WorkspaceHelper\n",
        "\n",
        "# Setup the widgets to collect required parameters.\n",
        "dbutils.widgets.dropdown(\"configure_for\", WorkspaceHelper.CONFIGURE_FOR_ALL_USERS, \n",
        "                         [WorkspaceHelper.CONFIGURE_FOR_ALL_USERS], \"Configure For (required)\")\n",
        "\n",
        "# lab_id is the name assigned to this event/class or alternatively its class number\n",
        "dbutils.widgets.text(WorkspaceHelper.PARAM_LAB_ID, \"\", \"Lab/Class ID (optional)\")\n",
        "\n",
        "# a general purpose description of the class\n",
        "dbutils.widgets.text(WorkspaceHelper.PARAM_DESCRIPTION, \"\", \"Description (optional)\")\n",
        "\n",
        "# The default spark version\n",
        "dbutils.widgets.text(WorkspaceHelper.PARAM_SPARK_VERSION, \"11.3.x-cpu-ml-scala2.12\", \"Spark Version (optional)\")\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "# MAGIC %md\n",
        "# MAGIC\n",
        "# MAGIC ## Run Init Script & Install Datasets\n",
        "# MAGIC Main purpose of the next cell is to pre-install the datasets.\n",
        "# MAGIC\n",
        "# MAGIC It has the side effect of create our DA object, which includes our REST client.\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "lesson_config.create_catalog = False                 # We don't need a schema when configuring the workspace\n",
        "lesson_config.create_schema = False                 # We don't need a schema when configuring the workspace\n",
        "\n",
        "DA = DBAcademyHelper(course_config, lesson_config)  # Create the DA object\n",
        "DA.reset_lesson()                                   # Reset the lesson to a clean state\n",
        "DA.init()                                           # Performs basic intialization including creating schemas and catalogs\n",
        "DA.conclude_setup()                                 # Finalizes the state and prints the config for the student\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "from dbacademy.dbhelper import ClustersHelper\n",
        "\n",
        "org_id = dbgems.get_org_id()\n",
        "lab_id = WorkspaceHelper.get_lab_id() or \"UNKNOWN\"\n",
        "spark_version = WorkspaceHelper.get_spark_version()\n",
        "workspace_name = WorkspaceHelper.get_workspace_name()\n",
        "workspace_description = WorkspaceHelper.get_workspace_description() or \"UNKNOWN\"\n",
        "\n",
        "print(f\"org_id:                {org_id}\")\n",
        "print(f\"lab_id:                {lab_id}\")\n",
        "print(f\"spark_version:         {spark_version}\")\n",
        "print(f\"workspace_name:        {workspace_name}\")\n",
        "print(f\"workspace_description: {workspace_description}\")\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "# MAGIC %md\n",
        "# MAGIC\n",
        "# MAGIC ## Create Class Instance Pools\n",
        "# MAGIC The following cell configures the instance pool used for this class\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "instance_pool_id = DA.workspace.clusters.create_instance_pool(preloaded_spark_version=spark_version,\n",
        "                                                              org_id=org_id, \n",
        "                                                              lab_id=lab_id, \n",
        "                                                              workspace_name=workspace_name, \n",
        "                                                              workspace_description=workspace_description)\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "# MAGIC %md\n",
        "# MAGIC\n",
        "# MAGIC ## Create The Three Class-Specific Cluster Policies\n",
        "# MAGIC The following cells create the various cluster policies used by the class\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "# org_id, lab_id, workspace_name and workspace_description are attached to the\n",
        "# instance pool and as such, they are not attached to the all-purpose or jobs policies.\n",
        "\n",
        "ClustersHelper.create_all_purpose_policy(client=DA.client, \n",
        "                                         instance_pool_id=instance_pool_id, \n",
        "                                         spark_version=spark_version,\n",
        "                                         autotermination_minutes_max=180,\n",
        "                                         autotermination_minutes_default=120)\n",
        "\n",
        "ClustersHelper.create_jobs_policy(client=DA.client, \n",
        "                                  instance_pool_id=instance_pool_id, \n",
        "                                  spark_version=spark_version)\n",
        "\n",
        "ClustersHelper.create_dlt_policy(client=DA.client, \n",
        "                                 org_id=org_id, \n",
        "                                 lab_id=lab_id, \n",
        "                                 workspace_name=workspace_name, \n",
        "                                 workspace_description=workspace_description)\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "# MAGIC %md\n",
        "# MAGIC\n",
        "# MAGIC ## Create Class-Shared Databricks SQL Warehouse/Endpoint\n",
        "# MAGIC Creates a single wharehouse to be used by all students.\n",
        "# MAGIC\n",
        "# MAGIC The configuration is derived from the number of students specified above.\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "from dbacademy.dbhelper.warehouses_helper_class import WarehousesHelper\n",
        "\n",
        "DA.workspace.warehouses.create_shared_sql_warehouse(name=WarehousesHelper.WAREHOUSES_DEFAULT_NAME)\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "# MAGIC %md\n",
        "# MAGIC\n",
        "# MAGIC ## Configure User Entitlements\n",
        "# MAGIC\n",
        "# MAGIC This task simply adds the \"**databricks-sql-access**\" entitlement to the \"**users**\" group ensuring that they can access the Databricks SQL view.\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "WorkspaceHelper.add_entitlement_workspace_access(client=DA.client)\n",
        "WorkspaceHelper.add_entitlement_databricks_sql_access(client=DA.client)\n",
        "\n",
        "# COMMAND ----------\n",
        "\n",
        "print(f\"Setup completed {dbgems.clock_stopped(setup_start)}\")\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}